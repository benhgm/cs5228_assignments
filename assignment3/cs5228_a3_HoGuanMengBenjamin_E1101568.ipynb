{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "763f0fa0-6584-44d4-b163-a891252769f9",
   "metadata": {},
   "source": [
    "# CS5228 Assignment 3 - Tree-Based Models\n",
    "\n",
    "Hello everyone, this assignment notebook covers Tree-Based Models. There are some code-completion tasks and question-answering tasks in this answer sheet. For code completion tasks, please write down your answer (i.e., your lines of code) between sentences that \"Your code starts here\" and \"Your code ends here\". The space between these two lines does not reflect the required or expected lines of code. For answers in plain text, you can refer to [this Markdown guide](https://medium.com/analytics-vidhya/the-ultimate-markdown-guide-for-jupyter-notebook-d5e5abf728fd) to customize the layout (although it shouldn't be needed).\n",
    "\n",
    "When you work on this notebook, you can insert additional code cells (e.g., for testing) or markdown cells (e.g., to keep track of your thoughts). However, before the submission, please remove all those additional cells again. Thanks!\n",
    "\n",
    "**Important:** \n",
    "* Rename and save this Jupyter notebook as **cs5228_a3_YourName_YourNUSNETID.ipynb** (e.g., **cs5228_a3_BobSmith_e12345678.ipynb**) before submission!\n",
    "* Rename and save the script file *cs5228_a3_script.py* as **cs5228_a3_YourName_YourNUSNETID.py** (e.g., **cs5228_a3_BobSmith_e12345678.py**) before submission!\n",
    "* Submission deadline is Oct 26, 11.59 pm. Late submissions will be penalized by 10% for each additional day. Failure to appropriately rename both files will yield a penalty of 1 Point. There is no need to use you full name if its a rather long; it's just  important to easily identify you in Canvas etc.\n",
    "\n",
    "Please also add your NUSNET and student id in the code cell below. This is just to make any identification of your notebook doubly sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119a3b10-7afe-4814-9a79-32310842f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = 'A0268269L'\n",
    "nusnet_id = 'E1101568'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7455d1c-31ad-4620-8d8a-ad2adc363f56",
   "metadata": {},
   "source": [
    "Here is an overview over the tasks to be solved and the points associated with each task. The notebook can appear very long and verbose, but note that a lot of parts provide additional explanations, documentation, or some discussion. The code and markdown cells you are supposed to complete are well, but you can use the overview below to double-check that you covered everything.\n",
    "\n",
    "* **1 Bagging and Feature Sampling (10 Points)**\n",
    "    * 1.1 Implement Bootstrapping (2 Points)\n",
    "    * 1.2 Implement Feature Sampling (2 Points)\n",
    "    * 1.3 Comparing Bagging and Bagging+FeatureSampling (6 Points)\n",
    "* **2 Implementing AdaBoost with Decision Stumps (30 Points)**\n",
    "    * 2.1 Implementing a Decision Stump Classifier (12 Points)\n",
    "        * 2.1 a) Calculating the Gini Score a Single Node (2 Points)\n",
    "        * 2.1 b) Calculating the Gini Score for a Split (2 Points)\n",
    "        * 2.1 c) Training the Decision Stump: Finding the Best Split (5 Points)\n",
    "        * 2.1 d) Predicting the Classes (3 Points)\n",
    "    * 2.2 Implementing AdaBoost (12 Points)\n",
    "        * 2.2 a) Training the Gradient-Boosted Regressor (8 Points)\n",
    "        * 2.2 b) Predicting Output Values (4 Points)\n",
    "    * 2.3 Questions about AdaBoost (6 Points)\n",
    "        * 2.3 a) Question 1 (2 Points)\n",
    "        * 2.3 b) Question 2 (4 Points)\n",
    "* **3 Evaluation of Tree-Based Models (10 Points)**\n",
    "    * 3.1 Data Preprocessing (2 Points)\n",
    "    * 3.2 Basic K-Fold Cross Validation (8 Points)\n",
    "        * 3.2a) Comparing Tree-Based Regression Models (5 Points)\n",
    "        * 3.2b) Assessing the Evaluation (3 Points)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60a4e6d6-30f8-4722-9750-4986c33fcccd",
   "metadata": {},
   "source": [
    "## Setting up the Notebook\n",
    "\n",
    "### Enable Auto-Reload\n",
    "\n",
    "This ensures that any saved changes to your `.py` file gets automatically reloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65641534-c0db-491c-8f9a-475ba94a5c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cad660cb-6a44-4906-8756-d18ec238bf09",
   "metadata": {},
   "source": [
    "### Enable \"Inline Plotting\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8067a9c2-d8d6-4cb5-b994-07fdc2c51b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1bdd634-a20d-491b-9339-49eab3ab7205",
   "metadata": {},
   "source": [
    "### Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca2bb72-8aa3-4d53-9d2a-e4953aa02592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "from src.utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "befecf0d-9ea3-4355-abb3-6cc7b1daa7ec",
   "metadata": {},
   "source": [
    "**Important:** This notebook also requires you to complete in a separate `.py` script file. This keeps this notebook cleaner and simplifies testing your implementations for us. As you need to rename the file `cs5228_a3.py`, you also need to edit the import statement below accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0827e5-fcc6-42d4-93df-96258a07cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cs5228_a3_SOLUTION import *\n",
    "from cs5228_a3_HoGuanMengBenjamin_E1101568 import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "872ccaa8-0df8-4b2c-9676-0f872ec645d8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e65ca2e-36ac-4d5e-aa5d-b5c5e39ba1a4",
   "metadata": {},
   "source": [
    "## 1 Bagging and Feature Sampling (10 Points)\n",
    "\n",
    "In the lecture, we discussed the limitations of individual Decision Trees, which motivated the notion of Tree Ensembles. In a nutshell, a Tree Ensemble trains multiple Decision Trees within the same classifier and regressor to reduce variance and improve accuracy. The first approach towards creating Tree Ensembles was to train multiple Decision Trees over different samples of the data:\n",
    "\n",
    "* **Bagging (Bootstrap Aggregation):** Sample a new dataset $D_i$ sampled from $D$ uniformly and with replacement ($|D_i| = |D|$)\n",
    "* **Feature Sampling:** For a given dataset $D$ with $d$ features, consider only a random subset of features of size $m$ with $m<d$.\n",
    "\n",
    "Combining Bagging and Feature Sampling is the underlying idea of *Random Forests*. In this task, you will explore the effects of Bagging and Bagging+FeatureSampling\n",
    "\n",
    "We use the very basic [IRIS](https://archive.ics.uci.edu/ml/datasets/iris) dataset: it's small and clean, and has only numerical features. The dataset contains 3 classes of 50 instances each, where each class refers to a type of iris plant.\n",
    "\n",
    "### Prepare Example Data\n",
    "\n",
    "#### Load Data from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a94584c-9786-461d-8a35-290468e44fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0           5.1          3.5           1.4          0.2        0\n",
       "1           4.9          3.0           1.4          0.2        0\n",
       "2           4.7          3.2           1.3          0.2        0\n",
       "3           4.6          3.1           1.5          0.2        0\n",
       "4           5.0          3.6           1.4          0.2        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/a3-iris.csv')\n",
    "\n",
    "# Convert the species name to numerical categories 0, 1, 2\n",
    "df['species'] = pd.factorize(df['species'])[0]\n",
    "\n",
    "# Show the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af5be1d5-ec05-4775-b65b-49072c231f5e",
   "metadata": {},
   "source": [
    "#### Convert to NumPy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69cfc1fb-102b-4daf-be5e-39c5d8196d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (150, 4)\n",
      "Shape of y: (150,)\n"
     ]
    }
   ],
   "source": [
    "data = df.to_numpy()\n",
    "\n",
    "X = data[:,0:4]\n",
    "y = data[:,4].astype(int)\n",
    "\n",
    "print('Shape of X: {}'.format(X.shape))\n",
    "print('Shape of y: {}'.format(y.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3644e33f-34d9-4925-9955-66fb240ce08e",
   "metadata": {},
   "source": [
    "### 1.1 Implement Bootstrapping (2 Points)\n",
    "\n",
    "Implement method `create_boostrap_sample()` to generate a bootstrap sample for a given dataset! The input dataset is represented by feature array `X` and array `y` containing the class labels (classification) or output values (regression). Hint: numpy provides some convenient methods to make this a very simple task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61eaec19-c816-44a7-af9c-3f50d8661b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_bootstrap: (150, 4)\n",
      "Shape of y_bootstrap: (150,)\n"
     ]
    }
   ],
   "source": [
    "def create_bootstrap_sample(X, y):\n",
    "    X_bootstrap, y_bootstrap = None, None\n",
    "\n",
    "    N, d = X.shape\n",
    "    \n",
    "    X_bootstrap, y_bootstrap = None, None\n",
    "    \n",
    "    #########################################################################################\n",
    "    ### Your code starts here ###############################################################\n",
    "    indices = np.random.randint(0, N, N)\n",
    "    \n",
    "    X_bootstrap = X[indices]\n",
    "    y_bootstrap = y[indices]\n",
    "    \n",
    "    ### Your code ends here #################################################################\n",
    "    #########################################################################################\n",
    "    \n",
    "    return X_bootstrap, y_bootstrap\n",
    "\n",
    "\n",
    "X_bootstrap, y_bootstrap = create_bootstrap_sample(X, y)\n",
    "\n",
    "print('Shape of X_bootstrap: {}'.format(X_bootstrap.shape))\n",
    "print('Shape of y_bootstrap: {}'.format(y_bootstrap.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb0e2b42-0489-4e61-93da-ba054196ab83",
   "metadata": {},
   "source": [
    "The shapes of `X_bootstrap` and `y_bootstrap` should of course be the same as the shapes of `X` and `y`, but containing randomly selected samples. If you need to convince yourself, you can also print some elements of `X` to see if they are different between runs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "216a2a40-da63-47ff-b950-739a2314dd00",
   "metadata": {},
   "source": [
    "### 1.2 Implement Feature Sampling (2 Points)\n",
    "\n",
    "Implement the method `perform_feature_sampling()`! The input is feature array `X`; use the common approach introduced in the lecture for calculating the number of sampled features -- that is, the number of sample features $m = \\lceil\\sqrt{d}\\rceil$. Apart from the new dataset `X_sample` the method also returns the *indices* of the selected features; we need those for the next task. Hint: Again, numpy should be your best friend here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5742cc84-b8c4-4d83-a75f-20e798a52b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_sampled: (150, 2)\n",
      "Selected indices: [1 1]\n"
     ]
    }
   ],
   "source": [
    "def perform_feature_sampling(X):\n",
    "    N, d = X.shape\n",
    "    \n",
    "    X_feature_sampled, selected_indices = None, None\n",
    "    \n",
    "    #########################################################################################\n",
    "    ### Your code starts here ###############################################################    \n",
    "\n",
    "    m = int(np.sqrt(d))\n",
    "    selected_indices = np.random.randint(0, d, m)\n",
    "    X_feature_sampled = X[:, selected_indices]\n",
    "    \n",
    "    \n",
    "    ### Your code ends here #################################################################\n",
    "    #########################################################################################    \n",
    "    \n",
    "    return X_feature_sampled, selected_indices\n",
    "    \n",
    "X_sampled, selected_indices = perform_feature_sampling(X)\n",
    "\n",
    "print('Shape of X_sampled: {}'.format(X_sampled.shape))\n",
    "print('Selected indices: {}'.format(selected_indices))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2311868-b59e-4de0-8114-e3563b0146b9",
   "metadata": {},
   "source": [
    "`X_sampled` has to contain the same number of data samples as `X`, but with less features than `X`. The number of selected indices should of course be reflected in the shape of `X`. For example, if the shape of `X` is $(n, m)$, then there should be $m$ selected indices."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a8f61fc-378a-4792-86ac-32765abe5857",
   "metadata": {},
   "source": [
    "### 1.3 Comparing Bagging and Bagging+FeatureSampling (6 Points)\n",
    "\n",
    "Intuitively, different sampled dataset will yield different Decision Trees, not only regarding the accuracy, but also how the Decision Trees will \"look like\". In the following, we train a set of Decision Trees (using the Decision Tree implementation from `sklearn`) based on different dataset samples.\n",
    "\n",
    "In the code cell below, we use our implementations of the auxiliary methods `create_boostrap_sample()` and `perform_feature_sampling()` to train a series of Decision Trees (i.e., a Tree Ensemble) using only Bagging as well as using Bagging + Feature Sampling. In the output, *root index* is the index of the feature used for the very first split, and *#nodes* reflects the total number of nodes in the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df219876-bcc2-4ccb-ba3f-6c06603b4f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging only\t\t\t\tBaggin + Feature Sampling\n",
      "root index: 3,  #nodes: 15\t\troot index: 0,  #nodes: 43\n",
      "root index: 2,  #nodes: 15\t\troot index: 2,  #nodes: 17\n",
      "root index: 2,  #nodes: 15\t\troot index: 2,  #nodes: 25\n",
      "root index: 2,  #nodes: 15\t\troot index: 2,  #nodes: 17\n",
      "root index: 2,  #nodes: 15\t\troot index: 0,  #nodes: 47\n",
      "root index: 3,  #nodes: 15\t\troot index: 2,  #nodes: 25\n",
      "root index: 2,  #nodes: 9\t\troot index: 1,  #nodes: 35\n",
      "root index: 2,  #nodes: 15\t\troot index: 1,  #nodes: 35\n",
      "root index: 3,  #nodes: 13\t\troot index: 2,  #nodes: 21\n",
      "root index: 3,  #nodes: 7\t\troot index: 3,  #nodes: 9\n",
      "root index: 3,  #nodes: 15\t\troot index: 3,  #nodes: 17\n",
      "root index: 2,  #nodes: 15\t\troot index: 3,  #nodes: 21\n",
      "root index: 2,  #nodes: 9\t\troot index: 2,  #nodes: 15\n",
      "root index: 2,  #nodes: 13\t\troot index: 0,  #nodes: 37\n",
      "root index: 3,  #nodes: 15\t\troot index: 2,  #nodes: 15\n",
      "root index: 3,  #nodes: 13\t\troot index: 2,  #nodes: 23\n",
      "root index: 3,  #nodes: 17\t\troot index: 3,  #nodes: 29\n",
      "root index: 2,  #nodes: 7\t\troot index: 3,  #nodes: 17\n",
      "root index: 2,  #nodes: 13\t\troot index: 2,  #nodes: 17\n",
      "root index: 2,  #nodes: 11\t\troot index: 3,  #nodes: 13\n"
     ]
    }
   ],
   "source": [
    "# We need to set the seed as the sampling is random, and we want to ensure consistent results\n",
    "np.random.seed(0)\n",
    "\n",
    "print(\"Bagging only\\t\\t\\t\\tBaggin + Feature Sampling\")\n",
    "\n",
    "for _ in range(20):\n",
    "    # Create a new bootstrap sample (we can use the same for both ensembles)\n",
    "    X_t, y_t = create_bootstrap_sample(X, y)\n",
    "    classifier_bagging = DecisionTreeClassifier().fit(X_t, y_t)\n",
    "        \n",
    "    # Perform feature sampling on bootstrap sample\n",
    "    X_t, selected_indices = perform_feature_sampling(X_t)\n",
    "    classifier_sampling = DecisionTreeClassifier().fit(X_t, y_t)\n",
    "    \n",
    "    # Print core features of trained Decision Tree\n",
    "    # (feature index of root node, total of number in Decision Trr)\n",
    "    print('root index: {},  #nodes: {}\\t\\troot index: {},  #nodes: {}'\n",
    "          .format(classifier_bagging.tree_.feature[0], classifier_bagging.tree_.node_count,\n",
    "                  selected_indices[classifier_sampling.tree_.feature[0]], classifier_sampling.tree_.node_count))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "645db041-fd10-4816-b656-edc571968081",
   "metadata": {},
   "source": [
    "**Interpret the result!** When comparing the resulting Decision Trees when using only **Bagging** and **Bagging+FeatureSampling** you must have observed several differences. List all your observations together with a brief explanation for the observed difference. What insights into the dataset can you gain from your observations?\n",
    "\n",
    "**Your Answer:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8064ac70-4598-4f13-a3b2-5166aca400d8",
   "metadata": {},
   "source": [
    "**__Observation__**\n",
    "Over the 20 iterations of the model, only features 2 and 3 are used in the root index for the bagging-only model. On the other hand, in the bagging + feature sampling model, we were able to use all the features as root index to split the trees during the 20 iterations.\n",
    "<br>\n",
    "\n",
    "**__Explanation__**\n",
    "In the bagging-only model, we can observe that features 2 and 3 are strong predictors hence they are always used in the root node to split the tree. To ensure that we cover all possible splits to get a more generalizable model, the feature sampling performed helps to only take out 2 features at a time to perform a split at the root node. As such, the occurrence of a strong predictor (feature 2 or 3) at the root node is reduced.\n",
    "\n",
    "**_Observation__**\n",
    "In the bagging + feature sampling model, there is generally a higher node count compared to the bagging-only model. This is especially apparent when features 0 and 1 are used as the root index.\n",
    "\n",
    "**__Explanation__**\n",
    "When using a strong predictor at the root to split the tree, we will get very distinct splits very early in the training and it will result in a smaller tree. However, with a weaker predictor, each split does not separate the dataset very well and produces more impure nodes, which allows us to split the tree further. Also, in the bagging only model, since we are using more features, we can always choose the best split among the 4 features for each split, and allowing us to arrive at the leaf faster. On the other hand, since there are only two features to select from in the bagging + feature sampling model, more splits will be required to arrive at the leaf.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc671f4a-59ae-41bd-bbd4-6cea9c075535",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5413b8a-3fef-4cb6-99ff-f88e6dcee636",
   "metadata": {},
   "source": [
    "## 2 Implementing a AdaBoost with Decision Stumps (30 Points)\n",
    "\n",
    "AdaBoost (Adaptive Boosting) is an ensemble learning method that combines the predictions of multiple base learners to improve overall classification performance. In AdaBoost, the base learners are typically weak learners, which are models that perform slightly better than random guessing (e.g., Decision Stumps). Here's a brief overview of how AdaBoost works using Decision Trees as base learners for classification tasks:\n",
    "\n",
    "* **Initialization:** Assign equal weights to all training samples. These weights determine the importance of each sample in the training process.\n",
    "\n",
    "* **Iterative Phase:**\n",
    "\n",
    "    * *Base Learner Training:* Train a base learner (usually a Decision Stump) on the training data. It tries to minimize the weighted classification error, giving more weight to misclassified samples.\n",
    "\n",
    "    * *Weighted Error Calculation:* Calculate the weighted classification error of the base learner. This error is the sum of the weights of misclassified samples.\n",
    "\n",
    "    * *Classifier Weight Calculation:* Assign a weight to the base learner based on its performance. The better the performance, the higher the weight. This weight is used to determine the contribution of the base learner's prediction in the final ensemble.\n",
    "\n",
    "    * *Update Sample Weights:* Increase the weights of misclassified samples so that they become more important in the next iteration. This focuses the subsequent base learners on the samples that are harder to classify correctly.\n",
    "\n",
    "    * *Ensemble Building:* Combine the predictions of all base learners, weighted by their individual classifier weights, to obtain the final ensemble prediction.\n",
    "\n",
    "* **Final Prediction:** The final prediction is made by aggregating the weighted predictions of all base learners.\n",
    "\n",
    "AdaBoost's strength lies in its ability to focus on the difficult-to-classify examples, allowing it to improve performance even with weak base learners. This makes it particularly effective in situations where a single base learner might struggle. Keep in mind that while AdaBoost is powerful, it's important to be cautious about overfitting. AdaBoost can overfit if the base learners are too complex or if the number of iterations is too high. Therefore, it's advisable to monitor the performance on a validation set and potentially use techniques like early stopping or limiting the complexity of base learners.\n",
    "\n",
    "Your last task will be to implement an AdaBoost Classifier using Decision Stumps as covered in the lecture. But not to worry, this may only sound more difficult than it actually is, and we will guide you through this process step by step. We also keep things simple by assuming that all input features are numerical values.\n",
    "\n",
    "Fundamentally, we can split the implementation into 2 subtasks.\n",
    "\n",
    "* **Weak Learner:** You first implement the simplest \"Decision Stump Classifier\", i.e., a Decision Tree with only one split and therefore a height of 1. This means we do not have to care about the recursive splitting of nodes; it's not complicated but would only add tedious coding.\n",
    "* **AdaBoost:** With the Decision Stump Classifier in place, you can implement AdaBoost as shown in the lecture."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12989e24-9943-4799-9d0e-0cd36c21448e",
   "metadata": {},
   "source": [
    "### Prepare Dataset\n",
    "\n",
    "Again, we use the [IRIS](https://archive.ics.uci.edu/ml/datasets/iris) dataset here.\n",
    "\n",
    "#### Load Dataset from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca04abbf-91c6-4eb3-b06d-75e882e35ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0           5.8          2.8           5.1          2.4        2\n",
       "1           6.0          2.2           4.0          1.0        1\n",
       "2           5.5          4.2           1.4          0.2        0\n",
       "3           7.3          2.9           6.3          1.8        2\n",
       "4           5.0          3.4           1.5          0.2        0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "df_iris = pd.read_csv('data/a3-iris.csv')\n",
    "# Convert the 3 string class labels to 0, 1, and 2\n",
    "df_iris.species = df_iris.species.factorize()[0]\n",
    "df_iris = df_iris.sample(frac=1).reset_index(drop=True)\n",
    "# Show sample of dataset\n",
    "df_iris.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dea35f1-368b-445f-9615-d4a55bdd633f",
   "metadata": {},
   "source": [
    "#### Convert Dataframe to NumPy arrays + Split into Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bda2a2fe-25e2-45bc-997d-270bafb821bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (30, 4)\n"
     ]
    }
   ],
   "source": [
    "X = df_iris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].to_numpy()\n",
    "y = df_iris['species'].to_numpy().squeeze()\n",
    "\n",
    "training_size = int(0.8 * X.shape[0])\n",
    "\n",
    "X_train, y_train = X[:training_size], y[:training_size]\n",
    "X_test, y_test = X[training_size:], y[training_size:]\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6be8cea0-007b-471d-b04d-9ab4eab864cd",
   "metadata": {},
   "source": [
    "### 2.1 Implementing a Decision Stump Classifier (12 Points)\n",
    "\n",
    "A Decision Stump is nothing else but a Decision Tree with typically only very few splits -- well, more generally, a Decision Tree with a (very) small height, but we keep it simple here. This means that we consider the smallest Decision Stump consisting of only a single split. This means that there is no need to continue recursively splitting child nodes like for a (full) Decision Tree trained to be a Strong Learner.\n",
    "\n",
    "For finding the best split, we need two main things\n",
    "* A scoring method to quantify how good a split is.\n",
    "* A method to actually find the best split (using the scoring method).\n",
    "\n",
    "You can find the skeleton code for the class `DecisionStumpClassifier` implementing the Decision Stump Classifier in the imported `py` file. You will need to complete this code step by step along with the subtask 2.1 a-d)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a64eae8-efa2-4921-813e-6ac1f9ebce35",
   "metadata": {},
   "source": [
    "#### 2.1 a) Calculating the Gini Score of a Single Node (2 Points)\n",
    "\n",
    "Recall from the lecture, that the Gini score of a node $t$ is defined as:\n",
    "\n",
    "$$Gini(t) = 1 - \\sum_{c\\in C} P(c|t)^2$$\n",
    "\n",
    "where $C$ is the set of classes, and $P(c|t)$ is the relative frequency of class $c$ in node $t$.\n",
    "\n",
    "**Implement this formula in the method `calc_gini_score_node()`!** Hint: Have a look at [`np.unique`](https://numpy.org/doc/stable/reference/generated/numpy.unique.html) and basic `numpy` methods such as [`np.sum`](https://numpy.org/doc/stable/reference/generated/numpy.sum.html) and [`np.square`](https://numpy.org/doc/stable/reference/generated/numpy.square.html) to make your life easier. You can use the example calls below to test your implementation of the method. The comments indicate the expected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52d1dc5d-f32f-4bda-9b8a-d284b7aaa52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.5\n",
      "0.625\n"
     ]
    }
   ],
   "source": [
    "stump = DecisionStumpClassifier()\n",
    "\n",
    "y1 = np.array([1, 1, 1, 1, 1, 1, 1, 1])\n",
    "y2 = np.array([0, 0, 0, 0, 1, 1, 1, 1])\n",
    "y3 = np.array([2, 0, 1, 1, 2, 2, 0, 2])\n",
    "\n",
    "print(stump.calc_gini_score_node(y1)) # 0.0\n",
    "print(stump.calc_gini_score_node(y2)) # 0.5\n",
    "print(stump.calc_gini_score_node(y3)) # 0.625"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f15d5dbb-393a-4d50-8283-65e070e01732",
   "metadata": {},
   "source": [
    "#### 2.1 b) Calculating the Gini Score for a Split (2 Points)\n",
    "\n",
    "In the lecture, we defined the impurity of a split as the average of the impurities of the child nodes, weighted by their size (in terms of the number of samples in each child node). Since we only consider binary splits (2 child nodes) and consider only the Gini score to measure impurity, the Gini score of a split simplifies to:\n",
    "\n",
    "$$Gini(t_{left}, t_{right}) = \\frac{n_{left}}{n}Gini(t_{left}) + \\frac{n_{right}}{n}Gini(t_{right})$$\n",
    "\n",
    "where $n_{left}$ ($n_{right}$) is the number of samples in the left (right) child node; and $n = n_{left} + n_{right}$\n",
    "\n",
    "**Implement this formula in the method `calc_gini_score_split`!** You obviously can and should use the existing method `calc_gini_score_node()`. You can use the example calls below to test your implementation of the method. The comments indicate the expected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec2c5d09-e78e-458e-ab5f-2ad413eb38fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.25\n",
      "0.3125\n"
     ]
    }
   ],
   "source": [
    "stump = DecisionStumpClassifier()\n",
    "\n",
    "print(stump.calc_gini_score_split(y1, y1))  # 0.0\n",
    "print(stump.calc_gini_score_split(y1, y2))  # 0.25\n",
    "print(stump.calc_gini_score_split(y1, y3))  # 0.3125"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2c975fd-2552-4071-b96f-73b0a69c44d0",
   "metadata": {},
   "source": [
    "#### 2.1 c) Training the Decision Stump: Finding the Best Split (5 Points)\n",
    "\n",
    "With the means to calculate the Gini score for an arbitrary split, we can now train our Decision Stump Classifier. Recall, that our Decision Tree will only have a height of 1 as we only need to make 1 split.\n",
    "\n",
    "**Implement method `fit()`** to find the best split with respect to all features and corresponding thresholds. You obviously can and should use of the existing method `calc_gini_score_split()`. The skeleton code of method `fit()` already provides with the nested loop that goes through all features and the respective thresholds. Note that we keep it simple here as we use all unique values of a features as candidate thresholds.\n",
    "\n",
    "You can use the example calls below to test your implementation of the method. The comments indicate the expected results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "385322ba-a8ac-4a48-84c9-4194b38a15e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of best feature: 2\n",
      "Best threshold: 2.45\n"
     ]
    }
   ],
   "source": [
    "stump = DecisionStumpClassifier().fit(X_train, y_train)\n",
    "\n",
    "print(\"Index of best feature:\", stump.feature_idx)\n",
    "print(\"Best threshold:\", stump.threshold)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53f5cd9b-d17e-4fe5-be7c-56626a9da316",
   "metadata": {},
   "source": [
    "The output of previous cell should be:\n",
    "\n",
    "```\n",
    "Index of best feature: 2\n",
    "Best threshold: 2.45\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d231267-03e5-48da-bbf7-ce8f77e4796b",
   "metadata": {},
   "source": [
    "#### 2.1 d) Predicting the Class Labels (3 Points)\n",
    "\n",
    "After training our Decision Stump Classifier, we now only need to implement the last step -- that is, the prediction of the class labels for new data samples. Again, since we only have 1 split, this step is also rather easy to implement.\n",
    "\n",
    "**Implement method `predict()`** to predict the class labels for a given set of data samples. Hint: Have again a look at [`np.unique`](https://numpy.org/doc/stable/reference/generated/numpy.unique.html) and and [`np.argmax`](https://numpy.org/doc/stable/reference/generated/numpy.square.html) to make your life easier. You can use the example calls below to test your implementation of the method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e44f9595-a004-447c-9324-4cc93a07069a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 0 2 0 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 2 0 0 0 2 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "stump = DecisionStumpClassifier().fit(X_train, y_train)\n",
    "\n",
    "print(stump.predict(X_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09c39a12-e5bf-4305-8979-b6ce9e3ca3ed",
   "metadata": {},
   "source": [
    "The output of previous cell should be:\n",
    "\n",
    "```\n",
    "[0. 2. 0. 0. 2. 0. 2. 2. 2. 2. 2. 2. 2. 2. 0. 2. 2. 2. 0. 2. 2. 2. 2. 0.\n",
    " 0. 0. 2. 2. 2. 0.]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8748b62f-e16f-4698-a558-f82f0a2bad01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of your Decision Tree implementation on the toy dataset is 0.540\n"
     ]
    }
   ],
   "source": [
    "y_pred = stump.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print('The f1 score of your Decision Tree implementation on the toy dataset is {:.3f}'.format(f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d52a989-c417-4e66-95b0-eb46f2737911",
   "metadata": {},
   "source": [
    "The resulting f1 score should be **0.540**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd3e6c48-4509-4fee-bf3e-c6248323a0de",
   "metadata": {},
   "source": [
    "**Testing your Implementation on the IRIS Dataset.** This part is only for you to test your implementation on a real-world dataset (IRIS) since the toy dataset might not reveal all bugs in your code. You can also directly compare the result your Decision Stump implementation with the results from scikit-learn's [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html); Of course, we need to set `max_depth=1` to make it a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eb8a27b-29d9-4a8e-94c7-e8c7fbcb45b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of your Decision Tree implementation on the IRIS dataset is 0.540\n",
      "The f1 score of sklearn Decision Tree implementation on the IRIS dataset is 0.540\n"
     ]
    }
   ],
   "source": [
    "my_stump = DecisionStumpClassifier().fit(X_train, y_train)\n",
    "sk_stump = DecisionTreeClassifier(max_depth=1).fit(X_train, y_train)\n",
    "\n",
    "my_y_pred = my_stump.predict(X_test)\n",
    "sk_y_pred = sk_stump.predict(X_test)\n",
    "\n",
    "my_f1 = f1_score(y_test, my_y_pred, average='macro')\n",
    "sk_f1 = f1_score(y_test, sk_y_pred, average='macro')\n",
    "\n",
    "print('The f1 score of your Decision Tree implementation on the IRIS dataset is {:.3f}'.format(my_f1))\n",
    "print('The f1 score of sklearn Decision Tree implementation on the IRIS dataset is {:.3f}'.format(sk_f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2c61b97-eac9-47b2-81d9-3f8082572c0d",
   "metadata": {},
   "source": [
    "You should see an f1 score of **0.540** using both your implementation as well as the one from scikit-learn."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef6b0839-d1df-40a5-8e15-fa5dfe538d5f",
   "metadata": {},
   "source": [
    "## 2.2 Implementing AdaBoost (12 Points)\n",
    "\n",
    "AdaBoost is a very popular ensemble technique that trains a series of *Weak Learners* to make predictions. Although AdaBoost is a generic technique, it is very commonly used with Decision Stumps as Weak Learners, since Decision Trees with a limited maximum height make naturally good Weak Learners.\n",
    "\n",
    "Again, we provide you with a skeleton code for the class implementing the AdaBoost Classifier. We call it `AdaBoostTreeClassifier` to avoid naming conflicts with `AdaBoostClassifier` of scikit-learn, and because we limit ourselves to Decision Trees (well, Stumps) as the estimators (i.e., the Weak Learners)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9409b98-9379-4b5a-bd39-c1fc38a4dae0",
   "metadata": {},
   "source": [
    "#### 2.1 a) Training the AdaBoost Classifier (8 Points)\n",
    "\n",
    "In the lecture, we went step by step through the training process of an AdaBoost classifier. We saw that this process comprises multiple but rather straightforward steps.\n",
    "\n",
    "\n",
    "**Implement method `fit()`** to train your `AdaBoostTreeClassifier`. The skeleton code of method `fit()` allows you to focus on the core steps within each iteration for training the next Weak Learner (here, our Decision Stump). To help you a little bit, we list the main 4 steps and give you the first step -- training the next estimator using the current dataset sample -- for free.\n",
    "\n",
    "**Important:** By default, `AdaBoostTreeClassifier` uses your implementation of `DecisionStumpClassifier` as its Weak Learner. In case you had problems implementing `DecisionStumpClassifier` or you simply want to test the results, you can also use scikit-learn's `DecisionTreeClassifier`. To make this change, just use the commented line under Step 1 to train the Weak Learner.\n",
    "\n",
    "You can use the example calls below to test your implementation of the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32a73cd4-2e7a-40d2-be68-3b76bef889ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alpha values -- i.e., the amount-of-says -- are:\n",
      "[0.36544375 0.54110924 0.61476166 0.64369347 0.50502969]\n"
     ]
    }
   ],
   "source": [
    "# We need to set the seed as the sampling is random\n",
    "np.random.seed(0)\n",
    "\n",
    "adaboost = AdaBoostTreeClassifier(n_estimators=5).fit(X_train, y_train)\n",
    "\n",
    "print(\"The alpha values -- i.e., the amount-of-says -- are:\")\n",
    "print(adaboost.alphas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56104f15-a1bb-4775-b178-559df6fad71c",
   "metadata": {},
   "source": [
    "The output of previous cell should be:\n",
    "\n",
    "```\n",
    "The alpha values -- i.e., the amount-of-says -- are:\n",
    "[0.36544375 0.54110924 0.65028309 0.65364937 0.53673646]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31473312-a14c-4ad4-b7a5-40914965af8d",
   "metadata": {},
   "source": [
    "#### 2.2 b) Predicting the Class Labels (5 Points)\n",
    "\n",
    "As the last step, we now only need our AdaBoost classifier to predict the class labels for unseen data samples. Again, we saw in the lecture how this works: For each data sample, we check which of the `n_estimators` estimators predicts a certain class label, and the sum of all the alphas (i.e., the amounts of say) of the estimators of the same class.\n",
    "\n",
    "The skeleton code of the `AdaBoostTreeClassifier` already provides a method `predict()` which takes a list of data samples as input and calls the method `predict_sample()` to predict the class label for each data sample individually. It's not that difficult to do this completely vectorized without the loop over the data samples, but here we want to focus on the basic algorithm and not worry about performance.\n",
    "\n",
    "**Implement method predict_sample()** to predict the class label for a given data sample. Hint: Have again a look at [np.argwhere](https://numpy.org/doc/stable/reference/generated/numpy.argwhere.html) to maybe make your life easier. You can use the example calls below to test your implementation of the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f037f2b0-2dbb-444a-9064-e9bf287e443c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 0 2 0 2 1 1 1 2 2 1 1 0 1 2 2 0 1 1 2 1 0 0 0 2 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "# We need to set the seed as the sampling is random\n",
    "np.random.seed(0)\n",
    "\n",
    "adaboost = AdaBoostTreeClassifier(n_estimators=5).fit(X_train, y_train)\n",
    "\n",
    "print(adaboost.predict(X_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a5f3b08-9358-475b-819a-fd54330b45bb",
   "metadata": {},
   "source": [
    "The output of previous cell should be:\n",
    "\n",
    "```\n",
    "[0 2 0 0 2 0 2 1 1 1 2 2 1 2 0 1 2 2 0 1 1 2 1 0 0 0 2 1 2 0]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "49bdb6f2-f184-419c-a271-f307da7f6fbd",
   "metadata": {},
   "source": [
    "**Testing your Implementation on the IRIS Dataset.** We the code cell below, you can again directly compare the result your AdaBoost implementation with the scikit-learn [`AdaBoostClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html). Two things to note:\n",
    "\n",
    "* By default, `AdaBoostClassifier` uses the `DecisionTreeClassifier` class as the estimators (i.e., the Weak Learners) with `max_depth=1`\n",
    "\n",
    "* By default, `AdaBoostClassifier` sets `n_estimators=50`; we therefore choose the same default value for `AdaBoostTreeClassifier`\n",
    "\n",
    "As a result, we do not have to set any parameters for `AdaBoostClassifier` and can use the default ones to allow for a fair comparison with your implementation of `AdaBoostTreeClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b52fc85-d2cf-4a3f-9b8b-11a25034bc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of your AdaBoost implementation on the IRIS dataset is 0.933\n",
      "The f1 score of the sklearn AdaBoost implementation on the IRIS dataset is 0.933\n"
     ]
    }
   ],
   "source": [
    "my_adaboost = AdaBoostTreeClassifier().fit(X_train, y_train)\n",
    "sk_adaboost = AdaBoostClassifier().fit(X_train, y_train)\n",
    "\n",
    "my_y_pred = my_adaboost.predict(X_test)\n",
    "sk_y_pred = sk_adaboost.predict(X_test)\n",
    "\n",
    "my_f1 = f1_score(y_test, my_y_pred, average='macro')\n",
    "sk_f1 = f1_score(y_test, sk_y_pred, average='macro')\n",
    "\n",
    "print('The f1 score of your AdaBoost implementation on the IRIS dataset is {:.3f}'.format(my_f1))\n",
    "print('The f1 score of the sklearn AdaBoost implementation on the IRIS dataset is {:.3f}'.format(sk_f1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f14028b-e090-47cf-870a-2b11e3645b8e",
   "metadata": {},
   "source": [
    "You should see an f1 score of **0.933** using both your implementation as well as the one from scikit-learn."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6649193e-eb67-4fac-88d0-b7450aff1a17",
   "metadata": {},
   "source": [
    "### 2.3 Questions about AdaBoost (6 Points)\n",
    "\n",
    "Assume you use your implementation of `AdaBoostTreeClassifier` to train a binary classifier of the dataset shown in 1.1 b).\n",
    "\n",
    "**2.3 a) Question (2 Points):** Will the binary classifier be able to achieve a training error (not test error!) of 0? Explain your answer! (Your explanation is more important than a simple Yes/No answer)\n",
    "\n",
    "**Your Answer:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "184a596b-add5-4acf-aa83-3755f6c4583c",
   "metadata": {},
   "source": [
    "Yes, it can achieve a training error of 0. As long as the number of iterations is large enough, the Adaboost Classifier will be able to achieve zero training error."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "678d899b-c099-4f05-b769-2d3d5c66fd59",
   "metadata": {},
   "source": [
    "**2.3 b) True/False Questions (4 Points):** In the table below are 4 statement that are either *True* or *False*. Complete the table to specify whether a statement is *True* or *False*, and provide a brief explanation for your answer (Your explanation is more important than a simple True/False answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7b080cf-91f9-477c-95cf-3827fbf96294",
   "metadata": {},
   "source": [
    "This is a markdown cell. Please fill in your answers for (1)~(4).\n",
    "\n",
    "| No. | Statement                                                                                               \t| True or False?   \t| Brief Explanation |\n",
    "|-----|------------------------------------------------------------------------------------------------------------|--------------| ------- |\n",
    "| (1)  | AdaBoost usually performs better than Random Forests when the dataset contains mislabeled data points | False | Both Adaboost and Random Forests depend on labelled data being correct to split the dataset. It is not certain that Adaboost performs better than RandomForest. |\n",
    "| (2)  | The error rate $\\epsilon_m$ of the Adaboost classifier always decreases from one iteration to the next. | True | For each iteration, misclassified samples are sampled with higer probability, which means that the classifier learns to predict more samples correctly after each iteration, leading to a lower error rate. |\n",
    "| (3)  | Assume an error rate of $\\epsilon_m \\leq 0.2$ in iteration $m$. This means that up to 20% of the data samples have been misclassified | False | This occurs in the worse case scenario and only if all the samples have equal weight, which is only at the start of the training. As the error rate depends on the weight of the sample for the iteration. For example, after m iterations, if only two samples out of 20 are misclassified, but they have a weight of 0.10 each then we will also get an error of 0.20, but only 10% of the sample is misclassified.|\n",
    "| (4)  | If after running AdaBoost the last Weak Learner does not misclassify and training samples, additional iterations could still help reduce errors on unseen data  | True | The model may have overfitted on the training data, but on unseen data, it is not for sure that the model will perform as well as on the training data. |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f0b77b56-8212-47a9-85e4-dae447301bbe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec2ac1ea-25f6-4d20-84d3-b3cec2f15d23",
   "metadata": {},
   "source": [
    "## 3 Evaluating Tree-Based Models\n",
    "\n",
    "In this last part, we look into evaluation different tree-based models using k-fold cross validationa. K-fold cross-validation is a technique used in machine learning to assess the performance and generalization ability of a model. It involves dividing the dataset into K subsets (or \"folds\") of equal size. The model is trained on K-1 of these folds and tested on the remaining one. This process is repeated K times, with each fold used as the test set exactly once. The final performance metric is computed by averaging the results from each iteration. K-fold cross-validation helps ensure that the model's performance is consistent across different subsets of the data, reducing the risk of overfitting or underfitting.\n",
    "\n",
    "### Prepare Dataset\n",
    "\n",
    "#### Load Dataset from File\n",
    "\n",
    "We use a [WHO Life Expectancy](https://www.kaggle.com/kumarajarshi/life-expectancy-who) dataset for this task. Note that we cleaned the dataset for you (i.e., there are no dirty records in there)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "643c9a75-171d-40e5-b060-eb6da2a5e5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Status</th>\n",
       "      <th>Adult Mortality</th>\n",
       "      <th>infant deaths</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>percentage expenditure</th>\n",
       "      <th>Hepatitis B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>BMI</th>\n",
       "      <th>under-five deaths</th>\n",
       "      <th>...</th>\n",
       "      <th>Total expenditure</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Population</th>\n",
       "      <th>thinness  1-19 years</th>\n",
       "      <th>thinness 5-9 years</th>\n",
       "      <th>Income composition of resources</th>\n",
       "      <th>Schooling</th>\n",
       "      <th>Life expectancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>Developing</td>\n",
       "      <td>263.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.01</td>\n",
       "      <td>71.279624</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1154</td>\n",
       "      <td>19.1</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>8.16</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>584.259210</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.479</td>\n",
       "      <td>10.1</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>Developing</td>\n",
       "      <td>271.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.523582</td>\n",
       "      <td>62.0</td>\n",
       "      <td>492</td>\n",
       "      <td>18.6</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>8.18</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>612.696514</td>\n",
       "      <td>327582.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.476</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>Developing</td>\n",
       "      <td>268.0</td>\n",
       "      <td>66</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.219243</td>\n",
       "      <td>64.0</td>\n",
       "      <td>430</td>\n",
       "      <td>18.1</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>8.13</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>631.744976</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.470</td>\n",
       "      <td>9.9</td>\n",
       "      <td>59.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>Developing</td>\n",
       "      <td>272.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>78.184215</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2787</td>\n",
       "      <td>17.6</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>8.52</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>669.959000</td>\n",
       "      <td>3696958.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.463</td>\n",
       "      <td>9.8</td>\n",
       "      <td>59.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>Developing</td>\n",
       "      <td>275.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.097109</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3013</td>\n",
       "      <td>17.2</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>7.87</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>63.537231</td>\n",
       "      <td>2978599.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.454</td>\n",
       "      <td>9.5</td>\n",
       "      <td>59.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year      Status  Adult Mortality  infant deaths  Alcohol  \\\n",
       "0  2015  Developing            263.0             62     0.01   \n",
       "1  2014  Developing            271.0             64     0.01   \n",
       "2  2013  Developing            268.0             66     0.01   \n",
       "3  2012  Developing            272.0             69     0.01   \n",
       "4  2011  Developing            275.0             71     0.01   \n",
       "\n",
       "   percentage expenditure  Hepatitis B  Measles   BMI  under-five deaths  ...  \\\n",
       "0               71.279624         65.0     1154  19.1                 83  ...   \n",
       "1               73.523582         62.0      492  18.6                 86  ...   \n",
       "2               73.219243         64.0      430  18.1                 89  ...   \n",
       "3               78.184215         67.0     2787  17.6                 93  ...   \n",
       "4                7.097109         68.0     3013  17.2                 97  ...   \n",
       "\n",
       "   Total expenditure  Diphtheria  HIV/AIDS         GDP  Population  \\\n",
       "0               8.16        65.0       0.1  584.259210  33736494.0   \n",
       "1               8.18        62.0       0.1  612.696514    327582.0   \n",
       "2               8.13        64.0       0.1  631.744976  31731688.0   \n",
       "3               8.52        67.0       0.1  669.959000   3696958.0   \n",
       "4               7.87        68.0       0.1   63.537231   2978599.0   \n",
       "\n",
       "   thinness  1-19 years  thinness 5-9 years  Income composition of resources  \\\n",
       "0                  17.2                17.3                            0.479   \n",
       "1                  17.5                17.5                            0.476   \n",
       "2                  17.7                17.7                            0.470   \n",
       "3                  17.9                18.0                            0.463   \n",
       "4                  18.2                18.2                            0.454   \n",
       "\n",
       "   Schooling  Life expectancy  \n",
       "0       10.1             65.0  \n",
       "1       10.0             59.9  \n",
       "2        9.9             59.9  \n",
       "3        9.8             59.5  \n",
       "4        9.5             59.2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/a3-life-expectancy-cleaned.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1acef995-4e5c-43d4-91d7-2d3ce24a73b0",
   "metadata": {},
   "source": [
    "#### Separate Features & Target\n",
    "\n",
    "For your convenience, we split the dataframe into two, one containing the input features, the other containing the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6b13268-9ac1-4990-b96e-89b3c4589487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 1649 samples with 20 features\n"
     ]
    }
   ],
   "source": [
    "df_X = df.iloc[:,0:-1]\n",
    "df_y = df.iloc[:,-1]\n",
    "\n",
    "num_samples, num_features = df_X.shape\n",
    "\n",
    "print('The dataset contains {} samples with {} features'.format(num_samples, num_features))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7b40b6b-0113-4838-8f31-06a30d2ee54a",
   "metadata": {},
   "source": [
    "### 3.1 Data Preprocessing (2 Points)\n",
    "\n",
    "As usual, the first step is data preprocessing (informed by an EDA). As mentioned above, there's not much to do as this dataset does not contain any \"dirty\" records, particularly, there are no NA values in any of the columns/features. As such, there should be no need to remove any samples.\n",
    "\n",
    "**Perform and data preprocessing/transformation steps you deem appropriate!** As it might affect your decision, the data will be used to train different tree-based models (recall: the tree-based classifiers of sklearn do not support categorical features!). Note that some preprocessing steps might be easier to perform on the pandas dataframe while others on the NumPy arrays. This is why we provide 2 code cells, but it's up to which one to use.\n",
    "\n",
    "**Note:** Perform only preprocessing steps that are indeed needed, and briefly(!) explain your decision by commenting your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da0cabed-075b-4289-a503-102b6b384a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "### Your code starts here ###############################################################\n",
    "\n",
    "# convert 'status' to 0: 'Developing', 1: 'Developed'. Use of ordinal encoding to preserve order of Developing -> Developed\n",
    "df_X['Status'] = df_X['Status'].replace({'Developing': 0, \"Developed\": 1})\n",
    "\n",
    "\n",
    "### Your code ends here #################################################################\n",
    "#########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb2fbae2-44cb-44ee-9868-9978dcd155dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframes to numpy arrays\n",
    "X, y = df_X.to_numpy(), df_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dec6ae36-908c-46af-839e-39c0946f1d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "### Your code starts here ###############################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Your code ends here #################################################################\n",
    "#########################################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecbf90b6-e701-4c0a-8acd-c0067c1a4ecc",
   "metadata": {},
   "source": [
    "### 3.2 Basic K-Fold Cross Validation\n",
    "\n",
    "The code cell below performs K-Fold Cross Validation. Note that we use `X` and `y` here, and assume our true test data for the final evaluation of the model(s) is a separate dataset. Since we only perform validation here, we can ignore the test data.\n",
    "\n",
    "The code cell below allows you to train a `DecisionTreeRegressor`, a `RandomForestRegressor`, or a `GradientBoostingRegressor` (all `sklearn` implementations). You only need to remove the comment before the regressor of choice, and comment the 2 other regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91afc3b3-73ea-4004-bbed-e40b73d1b01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param = 1, RSME training = 6.0 (0.1), RSME validation = 6.4 (0.9)\n",
      "param = 2, RSME training = 4.5 (0.1), RSME validation = 5.1 (0.8)\n",
      "param = 3, RSME training = 3.4 (0.1), RSME validation = 4.0 (0.8)\n",
      "param = 5, RSME training = 2.4 (0.1), RSME validation = 3.3 (0.4)\n",
      "param = 8, RSME training = 1.5 (0.1), RSME validation = 3.6 (0.5)\n",
      "param = 10, RSME training = 1.0 (0.1), RSME validation = 3.7 (0.4)\n",
      "param = 12, RSME training = 0.6 (0.1), RSME validation = 3.8 (0.5)\n",
      "param = 15, RSME training = 0.3 (0.1), RSME validation = 3.9 (0.4)\n",
      "param = 20, RSME training = 0.1 (0.0), RSME validation = 3.7 (0.5)\n",
      "param = 25, RSME training = 0.0 (0.0), RSME validation = 3.8 (0.4)\n",
      "param = 50, RSME training = 0.0 (0.0), RSME validation = 3.9 (0.6)\n",
      "CPU times: user 851 ms, sys: 3.98 ms, total: 855 ms\n",
      "Wall time: 854 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Only considered hyperparameter: max depth of trees\n",
    "param_choices = [1, 2, 3, 5, 8, 10, 12, 15, 20, 25, 50]\n",
    "\n",
    "# Keep track of results for visualization\n",
    "param_to_scores = {}\n",
    "\n",
    "for param in param_choices:\n",
    "\n",
    "    # Train regressor with the current parameter setting\n",
    "    regressor = DecisionTreeRegressor(max_depth=param)\n",
    "    # regressor = RandomForestRegressor(max_depth=param)\n",
    "    # regressor = GradientBoostingRegressor(max_depth=param)\n",
    "    \n",
    "    # Perform 10-fold cross_validations\n",
    "    scores = cross_validate(regressor, X, y, cv=10, scoring='neg_root_mean_squared_error', return_train_score=True)\n",
    "    \n",
    "    # Extract the 10 RSME scores (training scores and validation scores) for each run/fold\n",
    "    # The (-1) is only needed since we get the negative root mean squared errors (it's a sklearn thing)\n",
    "    rsme_train = scores['train_score'] * (-1)\n",
    "    rsme_valid = scores['test_score'] * (-1)\n",
    "    \n",
    "    ## Keep track of all num_folds f1 scores for current param (for plotting)\n",
    "    param_to_scores[param] = (rsme_train, rsme_valid)\n",
    "    \n",
    "    ## Print statement for some immediate feedback (values in parenthesis represent the Standard Deviation)\n",
    "    print('param = {}, RSME training = {:.1f} ({:.1f}), RSME validation = {:.1f} ({:.1f})'\n",
    "          .format(param, np.mean(rsme_train), np.std(rsme_train), np.mean(rsme_valid), np.std(rsme_valid)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a95be1c2-ea9f-4d24-8611-90e220798a37",
   "metadata": {},
   "source": [
    "**Visualization of Results.** We provide you with 2 methods to visualize the results:\n",
    "* `plot_validation_results()` shows all `num_folds` scores for each parameter setting together with the means and standard deviations of the validation scores.\n",
    "* `plot_scores()` shows the training and validation scores for each parameter setting.\n",
    "\n",
    "Just run the code cell below to plot both figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86510a8f-530d-4027-8507-8f2e11416909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_validation_results(param_to_scores)\n",
    "\n",
    "plot_scores(param_to_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c0fbca4-ff7a-475a-b104-0fc212e4a5b7",
   "metadata": {},
   "source": [
    "#### 3.2 a) Comparing Tree-Based Regression Models (5 Points)\n",
    "\n",
    "Run the k-fold cross validation for all 3 regressors and compare and discuss the results! You should see quite a number of differences regarding runtimes, issues of overfitting and underfitting, overall performance, effects of parameter values, etc. You can use the code cells above for cross validation and visualization.\n",
    "\n",
    "**Your Answer:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57b75e07-30d4-47cc-ae35-30e583a85658",
   "metadata": {},
   "source": [
    "### Runtime\n",
    "Recorded runtimes:<br>\n",
    "- Decision Tree: 854ms<br>\n",
    "- Random Forest: 54.9s<br>\n",
    "- Gradient Boost: 1min 20s\n",
    "\n",
    "As shown above, in terms of runtime, the decision tree was the fastest and the slowest was the gradient boosting method.\n",
    "\n",
    "### Overfitting Issue\n",
    "Both the decision tree and the gradient boosting methods were prone to overfitting, as can be observed by the training score approaching zero, while the validation score increased as the training score went down. On the other hand, the random forest model saw both training and validation scores progressing in the same directions throughout the training, which suggests that the model may not have overfitted as much as the other two models yet. The random forest model also has a slightly higher training loss which is expected since feature sampling and bagging is used to ensure that each tree in the forest does not overfit to the entire dataset.\n",
    "\n",
    "### Score Variance\n",
    "Comparing the variance of the RMSE scores of the K-fold cross validation models, we can observe that the gradient boost model has significantly higher variance over the 10-folds while the random forest model has a lower variance in RMSE scores. The lower variance in random forest could be attributed to the fact that strong predictors are not likely to be present in all the trees. This allows a balanced prediction outcome across each fold.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fe03c5b-dde9-4a18-8b6f-7de32d977d69",
   "metadata": {},
   "source": [
    "#### 3.2 b) Assessing the Evaluation (3 Points)\n",
    "\n",
    "Discuss if we found the regressor with the cross-validation result from above! There is no need to implement anything here.\n",
    "\n",
    "**Your Answer:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5dec8767-9a8d-4450-a2e1-cb006eb1c57b",
   "metadata": {},
   "source": [
    "Since all three models gave relatively similar results in terms of the final RMSE score (between 2.75 and 4.0), it is difficult to conclude which regressor is the best regressor to use. \n",
    "\n",
    "Even though the decision tre and gradient boost models displayed signs of overfitting, the final RMSE scores were still close to that of the random forest, which means that they could still give quite good predictions.\n",
    "\n",
    "Perhaps a good way is to combine three regressors and find the mean of the prediction, or use a majority voting system to get a final prediction. This is assuming space complexity and runtime requirements of any potential solution is not an issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b789fd9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

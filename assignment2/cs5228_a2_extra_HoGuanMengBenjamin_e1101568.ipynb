{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "763f0fa0-6584-44d4-b163-a891252769f9",
   "metadata": {},
   "source": [
    "# CS5228 Assignment 2 Extra\n",
    "\n",
    "Hello everyone, this assignment notebook covers Clustering using question-answering tasks. For the answers, you can refer to [this Markdown guide](https://medium.com/analytics-vidhya/the-ultimate-markdown-guide-for-jupyter-notebook-d5e5abf728fd) to customize the layout (although it shouldn't be needed).\n",
    "\n",
    "**Important:** \n",
    "* Rename and save this Jupyter notebook as **cs5228_a2_extra_YourName_YourNUSNETID.ipynb** (e.g., **cs5228_a2_BobSmith_e12345678.ipynb**) before submission!\n",
    "* Submission deadline is Sep 28, 11.59 pm. Late submissions will be penalized by 10% for each additional day. Failure to appropriately rename both files will yield a penalty of 1 Point. There is no need to use your full name if its a rather long; it's just  important to easily identify you in Canvas etc.\n",
    "\n",
    "Please also add your NUSNET and student id in the code cell below. This is just to make any identification of your notebook doubly sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119a3b10-7afe-4814-9a79-32310842f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = 'A0268269L'\n",
    "nusnet_id = 'E1101568'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7455d1c-31ad-4620-8d8a-ad2adc363f56",
   "metadata": {},
   "source": [
    "Here is an overview over the tasks to be solved and the points associated with each task. The notebook can appear very long and verbose, but note that a lot of parts provide additional explanations, documentation, or some discussion. The code and markdown cells you are supposed to complete are well, but you can use the overview below to double-check that you covered everything.\n",
    "\n",
    "* **4 Questions about Clustering (5 Points)**\n",
    "    * 4.1 DBSCAN on Scaled Data (2 Points)\n",
    "    * 4.2 K-Means++ with Deterministic Result (3 Points)Â¶"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "872ccaa8-0df8-4b2c-9676-0f872ec645d8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e65ca2e-36ac-4d5e-aa5d-b5c5e39ba1a4",
   "metadata": {},
   "source": [
    "## 4 Questions about Clustering (5 Points)\n",
    "\n",
    "### 4.1 DBSCAN on Scaled Data (2 Points)\n",
    "\n",
    "Assume you have a $d$-dimensional dataset `X` in the Euclidean space, i.e., each data point as $d$ numerical features (with each feature value in the interval $[0, 1]$). After running DBSCAN over `X`, you get some clustering (again, we only assume it's not only noise). Now you create a new dataset `X_new` by multiplying all data points by 10 afterwards adding 100 to all data points (in Python, assuming X is a NumPy array this can simply be done by `X_new = X * 10 + 100`). Now you can run DBSCAN over `X_new`.\n",
    "\n",
    "**Explain how you have to change the parameters of DBSCAN for `X_new` to get the same clusters as for `X`!**. You can ignore any corner cases like duplicate data points or the case where all the data points are noise points.\n",
    "\n",
    "**Your Answer:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f45047a8-929e-430a-9eb0-dd5ed9e11af9",
   "metadata": {},
   "source": [
    "We are able to obtain the same cluster by multiplying the value of $\\epsilon$ by 10, since the magnitude of the data has been scaled up by an order of 10."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51c4b827",
   "metadata": {},
   "source": [
    "### 4.2 K-Means++ with Deterministic Result (3 Points)\n",
    "\n",
    "Assume you have a $d$-dimensional dataset `X` in the Euclidean space, i.e., each data point as $d$ numerical features (with each feature value in the interval $[0, 1]$). You have 1,000 data points in total. Now you run K-Means with K-Means++ initialization and a value of K=20, yielding a clustering of 20 non-empty clusters.\n",
    "\n",
    "**Describe a data distribution of `X` where you will always get the same clustering when running K-Means++ with K=20!**. In other words, you run K-Means++ with K=20 again and again over X, and you will always get the same clustering. How must `X` \"look\" like to guarantee that?\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5eeba51a",
   "metadata": {},
   "source": [
    "The data distribution should have 20 fairly well-defined and well-separated peaks. Ideally, the distance between each cluster centroids should be greater than the sum of the radii of the clusters (assuming somewhat circular, blob-like clusters). So that any point between clusters have a high probability of being assigned to only one cluster and not another."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6de7fdd4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
